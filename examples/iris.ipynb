{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 modules: array, and nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml.array as ml\n",
    "import ml.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy-like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(11.904297, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = ml.Array([1,2,3,4])\n",
    "b = ml.Array([5,6,7,8])\n",
    "\n",
    "out = (a + b).sqrt().sum()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View computation graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26133835 0.6266034  0.435673   0.48981383]\n",
      " [0.25419953 0.6002871  0.42334855 0.47057244]]\n",
      "[[0.8678334  0.59258586]\n",
      " [0.64149284 0.44166332]\n",
      " [0.39418766 0.27127358]\n",
      " [0.9229811  0.63164824]]\n"
     ]
    }
   ],
   "source": [
    "a = ml.rand([2,4])\n",
    "b = ml.rand([4,2])\n",
    "c = ml.rand([2])\n",
    "out = (a @ b).sqrt().sum()\n",
    "\n",
    "# backward \n",
    "out.build_backward()\n",
    "print(a.grad().eval())\n",
    "print(b.grad().eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning: Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_data():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train = ml.Array(X_train.tolist())\n",
    "    X_test = ml.Array(X_test.tolist())\n",
    "    y_train = ml.Array(y_train.tolist())\n",
    "    y_test = ml.Array(y_test.tolist())\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def test_accuracy(W,b):\n",
    "    X_train, X_test, y_train, y_test = get_data()\n",
    "    logits_test = X_test.eval() @ W.eval() + b.eval()\n",
    "    predictions = np.argmax(logits_test, axis=1)\n",
    "    accuracy = np.mean((predictions == y_test.eval()))\n",
    "    print(f'Accuracy: {accuracy.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss =  1.0898603200912476\n",
      "10 loss =  0.3756318688392639\n",
      "20 loss =  0.24680905044078827\n",
      "30 loss =  0.176712304353714\n",
      "40 loss =  0.14138753712177277\n",
      "50 loss =  0.12131211161613464\n",
      "60 loss =  0.10833719372749329\n",
      "70 loss =  0.09953636676073074\n",
      "80 loss =  0.09285078197717667\n",
      "90 loss =  0.08762286603450775\n",
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, inp_shape, out_shape):\n",
    "        self.w = ml.rand([inp_shape,out_shape])\n",
    "        self.b = ml.rand([out_shape])\n",
    "        self.params = [self.w, self.b]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.w + self.b\n",
    "\n",
    "\n",
    "def train(lr, iter):\n",
    "    X_train, X_test, y_train, y_test = get_data()\n",
    "    one_hot_train = nn.one_hot_encode(y_train, 3)\n",
    "    \n",
    "    l = Linear(4,3)\n",
    "    logits = l(X_train)\n",
    "\n",
    "    # built in loss functions\n",
    "    loss = nn.softmax_cross_entropy_loss(logits, one_hot_train) \n",
    "    loss.build_backward()\n",
    "\n",
    "    # optimizers supported: Adam, SGD\n",
    "    optim = nn.Adam(lr, l.params)\n",
    "\n",
    "    # training loop\n",
    "    for it in range(iter):\n",
    "        if (it % (iter//10) == 0): print(f\"{it} loss = \", loss.eval().item())\n",
    "        loss.eval()\n",
    "        loss.zero_grad()\n",
    "        loss.set_reeval()\n",
    "        for p in l.params:\n",
    "            p.grad().set_reeval()\n",
    "        optim.step()\n",
    "    \n",
    "    test_accuracy(*l.params)\n",
    "    return loss\n",
    "\n",
    "lr = 0.01\n",
    "iter = 100\n",
    "\n",
    "loss = train(lr,iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view neural network graph\n",
    "loss.view_graph(view_data=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
